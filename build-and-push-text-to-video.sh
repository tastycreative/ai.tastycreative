#!/bin/bash

# Build and push RunPod Text to Video (Wan 2.2) Handler
# Usage: ./build-and-push-text-to-video.sh

set -e

# Configuration
DOCKER_IMAGE="rfldln01/text-to-video-wan22-handler"
VERSION="v1.0-text-to-video-$(date +%Y%m%d-%H%M%S)"
LATEST_TAG="latest"

echo "ğŸ‹ Building Docker image for RunPod Text to Video (Wan 2.2) Handler"
echo "ğŸ“¦ Image: $DOCKER_IMAGE"
echo "ğŸ·ï¸  Version: $VERSION"
echo "ğŸ—ï¸  Platform: linux/amd64"
echo ""

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker and try again."
    exit 1
fi

# Ensure buildx is available and create builder if needed
echo "ğŸ”§ Setting up Docker buildx for multi-platform builds..."
docker buildx create --name multiplatform --use --bootstrap 2>/dev/null || docker buildx use multiplatform

# Build and push amd64 image
echo "ğŸ”¨ Building and pushing Docker image for linux/amd64..."
docker buildx build \
    --platform linux/amd64 \
    -f Dockerfile.text-to-video \
    -t $DOCKER_IMAGE:$VERSION \
    -t $DOCKER_IMAGE:$LATEST_TAG \
    --push \
    .

echo ""
echo "ğŸ‰ Successfully built and pushed Docker image for linux/amd64!"
echo ""
echo "ğŸ“‹ USE THIS IN RUNPOD:"
echo "   Container Image: $DOCKER_IMAGE:$VERSION"
echo "   Or Latest: $DOCKER_IMAGE:$LATEST_TAG"
echo ""
echo "âœ¨ This version includes:"
echo "   â€¢ ğŸ¬ Wan 2.2 Text to Video Generation"
echo "   â€¢ âš¡ 4-step LoRA acceleration (high & low noise)"
echo "   â€¢ ğŸ¨ High-quality video synthesis from text prompts"
echo "   â€¢ ğŸ“ Custom prompt & negative prompt support"
echo "   â€¢ ğŸ”— Enhanced webhook system with retry logic"
echo "   â€¢ ğŸ“Š Comprehensive progress tracking"
echo "   â€¢ ğŸ›¡ï¸  Robust error handling and recovery"
echo "   â€¢ âš¡ Optimized for serverless RunPod deployments"
echo "   â€¢ ğŸ–¥ï¸  Platform: linux/amd64"
echo "   â€¢ ğŸ“¤ AWS S3 direct uploads for bandwidth optimization"
echo "   â€¢ ğŸ“ˆ Real-time progress tracking"
echo "   â€¢ ğŸ’¾ Network volume storage for models and outputs"
echo "   â€¢ ğŸ—‚ï¸  User-specific output folders (/runpod-volume/outputs/{userId}/)"
echo ""
echo "ğŸ¯ Supported Actions:"
echo "   â€¢ action='generate_text_to_video' (Text to Video generation)"
echo "   â€¢ action='health_check' (Check handler health)"
echo ""
echo "ğŸ” After deploying, check RunPod logs for debug messages like:"
echo "   ğŸ¯ Text to Video handler starting..."
echo "   ğŸ¨ Models loaded successfully..."
echo "   ğŸ“ Processing text prompt..."
echo "   âœ¨ Video generation started..."
echo "   âœ… Workflow validation passed..."
echo "   ğŸ¬ Output video processing completed..."
echo "   ğŸ“¤ AWS S3 upload completed..."
echo ""
echo "ğŸ“‹ Required Environment Variables:"
echo "   â€¢ AWS_ACCESS_KEY_ID (for S3 uploads)"
echo "   â€¢ AWS_SECRET_ACCESS_KEY (for S3 uploads)"
echo "   â€¢ AWS_S3_BUCKET (default: tastycreative)"
echo "   â€¢ AWS_REGION (default: us-east-1)"
echo ""
echo "ğŸ“ Required Models (should be in network volume):"
echo "   â€¢ diffusion_models/wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors"
echo "   â€¢ diffusion_models/wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors"
echo "   â€¢ text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors"
echo "   â€¢ vae/Wan2.1_VAE.safetensors"
echo "   â€¢ loras/wan2.2_t2v_lightx2v_4steps_lora_v1.1_high_noise.safetensors"
echo "   â€¢ loras/wan2.2_t2v_lightx2v_4steps_lora_v1.1_low_noise.safetensors"
echo ""
